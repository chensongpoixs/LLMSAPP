{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d00846",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# ---------------- é…ç½®éƒ¨åˆ† ----------------\n",
    "\n",
    "# è¯·æ›¿æ¢ä¸ºä½ çš„ API Keyï¼Œæˆ–è€…è®¾ç½®ç¯å¢ƒå˜é‡ GEMINI_API_KEY\n",
    "# https://aistudio.google.com/api-keys\n",
    "API_KEY = \"ä½ è‡ªå·±çš„API Key\"\n",
    "\n",
    "# è®¾ç½®ç›®æ ‡é¢˜ç›®æ•°é‡\n",
    "TOTAL_QUESTIONS = 1000\n",
    "# æ¯æ¬¡è¯·æ±‚è·å–çš„é¢˜ç›®æ•° (å»ºè®® 20-50 ä¹‹é—´ï¼Œé¿å…è¶…å‡ºå•æ¬¡è¾“å‡º Token é™åˆ¶)\n",
    "BATCH_SIZE = 50 \n",
    "# è¾“å‡ºæ–‡ä»¶å\n",
    "OUTPUT_FILE = \"math_problems_1000.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604ae050",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- 1. å®šä¹‰æå…¶ç®€å•çš„â€œæ¨¡å…·â€ ----------------\n",
    "# å‘Šè¯‰ Geminiï¼šæˆ‘åªè¦è¿™ä¸¤ä¸ªå­—æ®µï¼Œåˆ«çš„éƒ½ä¸è¦\n",
    "class SimpleQuestion(BaseModel):\n",
    "    grade: str = Field(description=\"å¹´çº§ï¼Œå¦‚ '4å¹´çº§'\")\n",
    "    content: str = Field(description=\"æ•°å­¦é¢˜ç›®çš„å…·ä½“å†…å®¹ï¼Œä¸åŒ…å«ç­”æ¡ˆ\")\n",
    "\n",
    "# ---------------- ä¸»ç¨‹åº ----------------\n",
    "def main():\n",
    "    client = genai.Client(api_key=API_KEY)\n",
    "    \n",
    "    all_data = [] # ç”¨æ¥å­˜æ‰€æœ‰çš„é¢˜ç›®\n",
    "    \n",
    "    print(f\"å¼€å§‹è·å– {TOTAL_QUESTIONS} é“çº¯æ•°å­¦é¢˜ (æ— ç­”æ¡ˆ)...\")\n",
    "\n",
    "    while len(all_data) < TOTAL_QUESTIONS:\n",
    "        # è®¡ç®—è¿˜è¦å¤šå°‘é“\n",
    "        needed = TOTAL_QUESTIONS - len(all_data)\n",
    "        current_batch_size = min(BATCH_SIZE, needed)\n",
    "        \n",
    "        print(f\"æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: {len(all_data)}/{TOTAL_QUESTIONS})\")\n",
    "\n",
    "        # æç¤ºè¯ï¼šæ˜ç¡®å‘Šè¯‰å®ƒä¸è¦ç­”æ¡ˆ\n",
    "        prompt = (\n",
    "            f\"è¯·ç»™æˆ‘ {current_batch_size} é“å°å­¦ 4-6 å¹´çº§çš„æ•°å­¦é¢˜ã€‚\"\n",
    "            \"è¦æ±‚ï¼š\\n\"\n",
    "            \"1. åªè¦é¢˜ç›®ï¼Œç»å¯¹ä¸è¦ç­”æ¡ˆï¼Œä¹Ÿä¸è¦é€‰é¡¹ã€‚\\n\"\n",
    "            \"2. é¢˜ç›®ç±»å‹åŒ…å«è®¡ç®—ã€åº”ç”¨é¢˜ã€å‡ ä½•ã€‚\\n\"\n",
    "            \"3. é¢˜ç›®æè¿°è¦æ¸…æ™°ã€‚\"\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\", # å»ºè®®ç”¨ Flashï¼Œé€Ÿåº¦å¿«ä¸”ä¾¿å®œï¼Œè¶³å¤Ÿç”Ÿæˆé¢˜ç›®\n",
    "                contents=prompt,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=list[SimpleQuestion], # å…³é”®ï¼šå¥—ç”¨ä¸Šé¢çš„ç®€å•æ¨¡å…·\n",
    "                    temperature=0.8,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            if response.parsed:\n",
    "                # æŠŠè¿™ä¸€æ‰¹é¢˜ç›®åŠ åˆ°æ€»åˆ—è¡¨é‡Œ\n",
    "                for item in response.parsed:\n",
    "                    all_data.append(item.model_dump())\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"å‡ºé”™é‡è¯•: {e}\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "            \n",
    "        time.sleep(1) # ç¨å¾®æ­‡ä¸€ä¸‹ï¼Œé˜²æ­¢è¯·æ±‚å¤ªå¿«\n",
    "\n",
    "    # ---------------- ä¿å­˜æ–‡ä»¶ ----------------\n",
    "    # æ„é€ æˆä½ æƒ³è¦çš„æ ¼å¼ { \"questions\": [ ... ] }\n",
    "    final_json = {\n",
    "        \"questions\": all_data\n",
    "    }\n",
    "\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(final_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"å®Œæˆï¼å·²ä¿å­˜åˆ° {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af47c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"math_dataset_with_answers.jsonl\"\n",
    "OUTPUT_FILE = \"incorrect_analysis.json\"\n",
    "\n",
    "# ä½¿ç”¨é€»è¾‘èƒ½åŠ›æœ€å¼ºçš„ Pro ç‰ˆæœ¬\n",
    "MODEL_NAME = \"gemini-2.5-pro\" \n",
    "\n",
    "# ---------------- 1. å®šä¹‰æ–°çš„è¾“å‡ºç»“æ„ ----------------\n",
    "\n",
    "# å®šä¹‰å•ä¸ªé”™è¯¯é¡¹ï¼šåŒ…å« ID å’Œ åŸå› \n",
    "class IncorrectItem(BaseModel):\n",
    "    id: int = Field(description=\"é¢˜ç›®å¯¹åº”çš„ ID ç¼–å·\")\n",
    "    reason: str = Field(description=\"ç®€çŸ­è§£é‡Šä¸ºä»€ä¹ˆè¿™é“é¢˜æ˜¯é”™çš„ï¼ˆä¾‹å¦‚ï¼š'è®¡ç®—é”™è¯¯ï¼Œ3+5åº”ä¸º8' æˆ– 'é€»è¾‘æ¨å¯¼æœ‰è¯¯'ï¼‰\")\n",
    "\n",
    "# å®šä¹‰æœ€ç»ˆè¿”å›çš„åˆ—è¡¨ç»“æ„\n",
    "class ReviewResult(BaseModel):\n",
    "    incorrect_items: list[IncorrectItem]\n",
    "\n",
    "# ---------------- ä¸»ç¨‹åº ----------------\n",
    "def main():\n",
    "    client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "    # 1. è¯»å–å¹¶ç»„è£…æ•°æ®\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"æ‰¾ä¸åˆ°æ–‡ä»¶: {INPUT_FILE}\")\n",
    "        return\n",
    "\n",
    "    print(f\"æ­£åœ¨è¯»å– {INPUT_FILE} ...\")\n",
    "    \n",
    "    full_content_for_prompt = \"\"\n",
    "    total_count = 0\n",
    "\n",
    "    with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        for index, line in enumerate(f):\n",
    "            line = line.strip()\n",
    "            if not line: continue\n",
    "            \n",
    "            try:\n",
    "                item = json.loads(line)\n",
    "                # ç»„è£…æ–‡æœ¬ï¼Œæ˜ç¡®æ ‡å‡º ID\n",
    "                record_str = (\n",
    "                    f\"ID: {index}\\n\"\n",
    "                    f\"Question: {item.get('instruction')}\\n\"\n",
    "                    f\"Thinking: {item.get('thinking')}\\n\"\n",
    "                    f\"Answer: {item.get('output')}\\n\"\n",
    "                    f\"-----------------------------\\n\"\n",
    "                )\n",
    "                full_content_for_prompt += record_str\n",
    "                total_count += 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    print(f\"ç»„è£…å®Œæˆï¼Œå…± {total_count} æ¡æ•°æ®ã€‚\")\n",
    "    print(f\"æ­£åœ¨å‘é€ç»™ {MODEL_NAME} è¿›è¡Œæ·±åº¦æ£€æŸ¥...\")\n",
    "    print(\"è¿™å¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...\")\n",
    "\n",
    "    # 2. æ„é€ æç¤ºè¯\n",
    "    prompt = (\n",
    "        \"ä½ æ˜¯ä¸€ä½èµ„æ·±æ•°å­¦è€å¸ˆã€‚è¯·ä»”ç»†æ£€æŸ¥ä»¥ä¸‹æ‰€æœ‰æ•°å­¦é¢˜çš„ã€æ¨ç†è¿‡ç¨‹ã€‘å’Œã€æœ€ç»ˆç­”æ¡ˆã€‘ã€‚\\n\"\n",
    "        \"å¦‚æœå‘ç°ä»»ä½•é”™è¯¯ï¼ˆè®¡ç®—é”™è¯¯ã€é€»è¾‘è°¬è¯¯ã€æˆ–è€…ç­”æ¡ˆé”™è¯¯ï¼‰ï¼Œè¯·å°†å…¶è®°å½•ä¸‹æ¥ã€‚\\n\"\n",
    "        \"\\n\"\n",
    "        \"ä»»åŠ¡è¦æ±‚ï¼š\\n\"\n",
    "        \"1. å¦‚æœé¢˜ç›®å®Œå…¨æ­£ç¡®ï¼Œå¿½ç•¥å®ƒã€‚\\n\"\n",
    "        \"2. å¦‚æœæœ‰é”™ï¼Œè¯·è®°å½•å…¶ IDï¼Œå¹¶ç”¨ç®€çŸ­çš„ä¸­æ–‡è¯´æ˜é”™è¯¯åŸå› ã€‚\\n\"\n",
    "        \"3. ä¸¥æ ¼æŒ‰ç…§å®šä¹‰çš„ JSON æ ¼å¼è¿”å›ç»“æœã€‚\\n\"\n",
    "        \"\\n\"\n",
    "        \"ä»¥ä¸‹æ˜¯å¾…æ£€æŸ¥çš„é¢˜ç›®åˆ—è¡¨ï¼š\\n\"\n",
    "        f\"{full_content_for_prompt}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # 3. è°ƒç”¨ API\n",
    "        response = client.models.generate_content(\n",
    "            model=MODEL_NAME,\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=ReviewResult, # å…³é”®ï¼šä½¿ç”¨æ–°çš„ç»“æ„\n",
    "                temperature=0.1, # ä½æ¸©åº¦ä¿è¯ä¸¥è°¨\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # 4. è§£æç»“æœ\n",
    "        if response.parsed:\n",
    "            errors = response.parsed.incorrect_items\n",
    "            \n",
    "            # æŒ‰ ID æ’åºï¼Œæ–¹ä¾¿æŸ¥çœ‹\n",
    "            errors.sort(key=lambda x: x.id)\n",
    "            \n",
    "            print(\"-\" * 50)\n",
    "            if not errors:\n",
    "                print(\"ğŸ‰ å¤ªæ£’äº†ï¼Gemini æ²¡æœ‰å‘ç°ä»»ä½•é”™è¯¯ï¼Œå…¨å¯¹ï¼\")\n",
    "            else:\n",
    "                print(f\"æ£€æŸ¥å®Œæˆï¼å…±å‘ç° {len(errors)} ä¸ªé”™è¯¯ï¼š\\n\")\n",
    "                \n",
    "                # æ‰“å°åˆ°æ§åˆ¶å°é¢„è§ˆ\n",
    "                for item in errors[:10]: # åªæ‰“å°å‰10ä¸ªé¿å…åˆ·å±\n",
    "                    print(f\"[ID: {item.id}] âŒ {item.reason}\")\n",
    "                \n",
    "                if len(errors) > 10:\n",
    "                    print(f\"... è¿˜æœ‰ {len(errors)-10} ä¸ªé”™è¯¯æœªæ˜¾ç¤ºã€‚\")\n",
    "\n",
    "                # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨ä»¥ä¾¿ä¿å­˜\n",
    "                save_data = [item.model_dump() for item in errors]\n",
    "\n",
    "                # ä¿å­˜åˆ°æ–‡ä»¶\n",
    "                with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(save_data, f, ensure_ascii=False, indent=2)\n",
    "                \n",
    "                print(f\"\\nå®Œæ•´é”™è¯¯æŠ¥å‘Šå·²ä¿å­˜è‡³: {OUTPUT_FILE}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"API è¿”å›å†…å®¹æ— æ³•è§£æã€‚\")\n",
    "            print(\"åŸå§‹è¿”å›:\", response.text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¯·æ±‚å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a9762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "print(\"æ­£åœ¨åˆ—å‡ºå¯ç”¨æ¨¡å‹...\")\n",
    "try:\n",
    "    # æ–°ç‰ˆ SDK çš„ list æ–¹æ³•è¿”å›çš„æ˜¯ä¸€ä¸ªè¿­ä»£å™¨\n",
    "    for model in client.models.list():\n",
    "        # ç›´æ¥æ‰“å° model.nameï¼Œä¸è¿›è¡Œå±æ€§è¿‡æ»¤ï¼Œé˜²æ­¢æŠ¥é”™\n",
    "        print(f\"- {model.name}\")\n",
    "        # å¦‚æœä½ æƒ³çœ‹å®ƒçš„æ‰€æœ‰å±æ€§ï¼Œå¯ä»¥ç”¨ print(model.model_dump())\n",
    "except Exception as e:\n",
    "    print(f\"æŸ¥è¯¢å‡ºé”™: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
