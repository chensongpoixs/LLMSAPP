# 梯度下降


什么是梯度下降

1. <font color='red'>用来找到函数局部最小值的算法</font>


### 代价函数的最小值

1. 当找到代价函数的最小值， 就找到了最佳的w和b
2. 找到了最佳的w和b， 就找到了线性回归的最佳模型
3. 对于深度学习网络， 也是要找到其代价函数的最小值
4. 使用的方法就是<font color='red'>梯度下降</font>

## 1、梯度下降的目标

1. 线型回归模型，找到minimize(J(w, b))
2. 深度学习模型， 找到minimize(J(w1, w2, w3, ..., wn, b))


## 2、 梯度下降的过程

![梯度下降的过程](/deeplearn/gradient_descent_paths.svg)

- 不同起点， 会到不同的局部最小值



