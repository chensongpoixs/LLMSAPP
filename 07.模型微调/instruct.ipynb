{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed68cde3",
   "metadata": {},
   "source": [
    "# ‰∏Ä„ÄÅ Âä†ËΩΩDatasetÊï∞ÊçÆÈõÜ\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bfb17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"instruction-data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data[1])\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07122ed",
   "metadata": {},
   "source": [
    "# ‰∫å„ÄÅ ÈÄÅËÆ≠ÁªÉ requestÂíåresponseÊ†ºÂºè\n",
    "\n",
    "```javascript \n",
    "\n",
    "\"Below is an instruction that describes a task.\"\n",
    "\"Write a response that appropriately completes the request.\"\n",
    "\"\\n\\n### Instruction:\\n   instruction\"\n",
    "\n",
    "\"\\n\\n### Input:\\n input\" \n",
    "\n",
    " \n",
    "\"\\n\\n### Response:\\noutput\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff535966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(item):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task.\"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{item['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{item['input']}\" if item[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text\n",
    "\n",
    "myinput = format_input(data[50])\n",
    "response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(myinput+response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a28f7e",
   "metadata": {},
   "source": [
    "# ‰∏â„ÄÅ ËÆ≠ÁªÉÊï∞ÊçÆÈõÜ„ÄÅÈ™åËØÅÊï∞ÊçÆÈõÜ„ÄÅÊµãËØïÊï∞ÊçÆËß£ÁöÑÊØîÂàó\n",
    "\n",
    "ËÆ≠ÁªÉÊï∞ÊçÆÈõÜ:80%\n",
    "\n",
    "È™åËØÅÊï∞ÊçÆÈõÜ:10%\n",
    "\n",
    "ÊµãËØïÊï∞ÊçÆÈõÜ:10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52569fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8:1:1\n",
    "train_part = (int)(len(data) *0.8)\n",
    "val_part = (int)(len(data)*0.1)\n",
    "test_part = len(data)-train_part - val_part\n",
    "\n",
    "train_data = data[:train_part]\n",
    "val_data = data[train_part:train_part+val_part]\n",
    "test_data = data[train_part+val_part:]\n",
    "\n",
    "print(\"train set length:\", len(train_data))\n",
    "print(\"val set length:\", len(val_data))\n",
    "print(\"test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba477ee",
   "metadata": {},
   "source": [
    "# Âõõ„ÄÅÊûÑÂª∫DatasetÁöÑÊï∞ÊçÆÈõÜ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.samples = []\n",
    "        for i in data:\n",
    "            input = format_input(i)\n",
    "            response = f\"\\n\\n### Response:\\n{i['output']}\"\n",
    "            full_text = input + response\n",
    "            self.samples.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.samples[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f3e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch;\n",
    "\n",
    "# def my_collate_fn(\n",
    "#     batch,\n",
    "#     pad_token_id=50256,\n",
    "#     ignore_token_id=-100,\n",
    "#     allowed_max_length=None, # ÊúÄÂ§ß\n",
    "#     device=\"cuda\"  # ÈªòËÆ§cpuËÆæÂ§á\n",
    "# ):\n",
    "#     # Ëé∑ÂèñËøô‰∏™ÊâπÊ¨°‰∏≠ÊúÄÈïøÊ†∑Êú¨ÁöÑÈïøÂ∫¶\n",
    "#     batch_max_len = max(len(i) +1 for i in batch );\n",
    "\n",
    "#     # ËæìÂÖ•ÂàóË°®ÂíåÁõÆÊ†áÂàóË°®\n",
    "#     input_list, target_list = [], [];\n",
    "\n",
    "#     for i in batch:\n",
    "#         # 1. Â∞ÜËøô‰∏™ÊâπÊ¨°‰∏≠Â∞è‰∫éÊâπÊ¨°ÊúÄÂ§ßÈïøÂ∫¶ÁöÑÊâÄÊúâÊ†∑Êú¨ËøõË°åÂ°´ÂÖÖ\n",
    "\n",
    "#         # 2. Ê†πÊçÆËæìÂÖ•ÂàõÂª∫targets\n",
    "\n",
    "#         # 3. Â∞Ütargets‰∏≠Â°´ÂÖÖÁöÑtoken_idÊõøÊç¢Êàê-100(Èô§‰∫ÜÁ¨¨‰∏Ä‰∏™ÁöÑÂ°´ÂÖÖtokenid‰πãÂ§ñ)\n",
    "#         new_item = i + [pad_token_id];\n",
    "#         padded = new_item +[pad_token_id] * (batch_max_len - len(new_item));\n",
    "\n",
    "#         inputs = torch.tensor( padded[:-1]);\n",
    "#         targets = torch.tensor(padded[1:]);\n",
    "\n",
    "#         # targets  = [ 1 2 3   50256   50256 50256 ...]\n",
    "#         # mask = [False, False, False True, True ...] \n",
    "#         mask = targets == pad_token_id;\n",
    "\n",
    "#         slice = torch.nonzero(mask).sqeeze();\n",
    "#         #slice = torch.nonzero(mask);\n",
    "#         # ‰∏çÂè™‰∏Ä‰∏™Â§ß‰∫é1\n",
    "#         if slice.numel() > 1:\n",
    "#             targets[slice[1:]] = ignore_token_id;\n",
    "\n",
    "#         if allowed_max_length is not None:\n",
    "#             inputs = inputs[:allowed_max_length];\n",
    "#             targets = targets[:allowed_max_length];\n",
    "\n",
    "#         input_list.append(inputs);\n",
    "#         target_list.append(targets);\n",
    "\n",
    "#     input_tensor = torch.stack(input_list).to(device);\n",
    "\n",
    "#     target_tensor = torch.stack(target_list); # .to(device);\n",
    "\n",
    "#     return input_tensor, target_tensor;\n",
    "\n",
    "\n",
    "def my_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_token_id=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    #Ëé∑ÂèñËøô‰∏™ÊâπÊ¨°‰∏≠ÊúÄÈïøÊ†∑Êú¨ÁöÑÈïøÂ∫¶\n",
    "    batch_max_len = max(len(i)+1 for i in batch)\n",
    "    #bacth_max_len = max(len(i)+1 for i in batch)\n",
    "    input_list, target_list = [], []\n",
    "\n",
    "    for i in batch:\n",
    "        #Â∞ÜËøô‰∏™ÊâπÊ¨°‰∏≠Â∞è‰∫éÊâπÊ¨°ÊúÄÂ§ßÈïøÂ∫¶ÁöÑÊâÄÊúâÊ†∑Êú¨ËøõË°åÂ°´ÂÖÖ\n",
    "        #Ê†πÊçÆËæìÂÖ•ÂàõÂª∫targets\n",
    "        #Â∞Ütargets‰∏≠Â°´ÂÖÖÁöÑtoken_idÊõøÊç¢Êàê-100ÔºàÈô§Á¨¨‰∏Ä‰∏™Â°´ÂÖÖÁöÑtokenid‰πãÂ§ñÔºâ\n",
    "        new_item = i + [pad_token_id]\n",
    "        padded = new_item + [pad_token_id] * (batch_max_len - len(new_item))\n",
    "        #padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        # targets = [1 2 3 50256 50256 ...],\n",
    "        # mask = [False, False, False, True, True ...]\n",
    "        mask = targets == pad_token_id\n",
    "        slice = torch.nonzero(mask).squeeze()\n",
    "        if slice.numel() > 1:\n",
    "            targets[slice[1:]] = ignore_token_id\n",
    "        \n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        \n",
    "        input_list.append(inputs)\n",
    "        target_list.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(input_list).to(device)\n",
    "    #targets_tensor = troch.stack(target_list)\n",
    "    targets_tensor = torch.stack(target_list)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a159052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mask = [False, True, False, True, True, False, True, True];\n",
    "# # ÊâìÂç∞Èùû FalseÁöÑ‰∏ãÊ†á\n",
    "# print(torch.nonzero(torch.tensor(test_mask)));\n",
    "# # ‰∫åÁª¥Âèò‰∏ÄÁª¥\n",
    "# slice = torch.nonzero(torch.tensor(test_mask)).squeeze();\n",
    "# print(slice);\n",
    "\n",
    "\n",
    "# targets = torch.tensor([1, 34, 4, 5, 6, 50256, 50256, 50256]);\n",
    "# # ÂâçÈù¢‰∏âÈ°π‰∏çÂä® ÊîπÂèòÂêéÈù¢ÁöÑÊï∞Â≠ó\n",
    "# targets[slice[1:]] = -100;\n",
    "# print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from functools import partial\n",
    "customized_collate_fn = partial(my_collate_fn, \n",
    "                                device=device,\n",
    "                                allowed_max_length=1024)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c157eaf",
   "metadata": {},
   "source": [
    "# ‰∫î„ÄÅÂä†ËΩΩ ËÆ≠ÁªÉ„ÄÅÈ™åËØÅÊï∞ÊçÆÈõÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f9716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Âä†ËΩΩÊï∞ÊçÆÈõÜ\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = customized_collate_fn,\n",
    "    shuffle = True,\n",
    "    drop_last = True\n",
    ")\n",
    "\n",
    "#È™åËØÅÊï∞ÊçÆÈõÜ\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = customized_collate_fn,\n",
    "    shuffle = False,\n",
    "    drop_last = False\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = customized_collate_fn,\n",
    "    shuffle = False,\n",
    "    drop_last = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4978fbc8",
   "metadata": {},
   "source": [
    "# ÂÖ≠„ÄÅÂä†ËΩΩOpenAi-GPT2Ê®°Âûã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89112e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai-community/gpt2/resolve/main/config.json (Caused by ConnectTimeoutError(<HTTPSConnection(host='huggingface.co', port=443) at 0x1619ca66050>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 1e42ddc3-ea9d-48bd-b864-ec0f603f6a80)')' thrown while requesting HEAD https://huggingface.co/openai-community/gpt2/resolve/main/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai-community/gpt2/resolve/main/config.json (Caused by ConnectTimeoutError(<HTTPSConnection(host='huggingface.co', port=443) at 0x1619ca67460>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 08aaf6ba-5122-444c-9b3d-8b592549b0a0)')' thrown while requesting HEAD https://huggingface.co/openai-community/gpt2/resolve/main/config.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai-community/gpt2/resolve/main/config.json (Caused by ConnectTimeoutError(<HTTPSConnection(host='huggingface.co', port=443) at 0x1619ca66470>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 022da1cf-e2c7-4d2d-a3a0-5669a883141f)')' thrown while requesting HEAD https://huggingface.co/openai-community/gpt2/resolve/main/config.json\n",
      "Retrying in 8s [Retry 4/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/3] ÂºÄÂßãÊùÉÈáçÁßªÊ§ç...\n",
      "  -> Ê≠£Âú®Âä†ËΩΩ Embeddings (wte, wpe)...\n",
      "  -> Ê≠£Âú®Âä†ËΩΩ 12 Â±Ç Transformer Block...\n",
      "  -> Ê≠£Âú®Âä†ËΩΩ Final LayerNorm & Head...\n",
      "[3/3] ÊàêÂäüÔºÅGPT-2 ÊùÉÈáçÂ∑≤ÂÖ®ÈÉ®Âä†ËΩΩÂÆåÊàê„ÄÇ\n",
      "\n",
      "Ê®°ÂûãÂ∑≤Âä†ËΩΩËá≥Ôºöcuda\n"
     ]
    }
   ],
   "source": [
    "from GPTModel import MyGPTModel, generate_new, text_to_tokenids, tokenids_to_text\n",
    "from load_gpt2_model import load_gpt2_weights\n",
    "import torch\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"max_seq_length\": 1024,\n",
    "    \"embedding_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": True\n",
    "};\n",
    "model = MyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "load_gpt2_weights(model, GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Ê®°ÂûãÂ∑≤Âä†ËΩΩËá≥Ôºö{device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0442c2a",
   "metadata": {},
   "source": [
    "#  ÂÖ´„ÄÅ Âä†ËΩΩÊ®°Âûã Êé®ÁêÜdemo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa5aed3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:OpenAI is the first game to be built specifically for the platform. It's based on a popular AI software, and includes tools for building games to be played on\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "prompt = \"OpenAI is\"\n",
    "prompt = text_to_tokenids(prompt, tokenizer).to(device)\n",
    "tokens = generate_new(model, \n",
    "             prompt,\n",
    "             30,\n",
    "             GPT_CONFIG_124M[\"max_seq_length\"],\n",
    "             25,\n",
    "             1.2)\n",
    "\n",
    "print(f\"output:{tokenids_to_text(tokens, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e434076",
   "metadata": {},
   "source": [
    "# ‰πù„ÄÅ Êåá‰ª§ÂæÆË∞É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0403d9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: tensor(4., device='cuda:0')\n",
      "Validation loss: tensor(4., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from GPTModel import calc_loss\n",
    "with torch.no_grad():\n",
    "        train_loss = calc_loss(train_dataloader, model, device)\n",
    "        val_loss = calc_loss(val_dataloader, model, device)\n",
    "\n",
    "\n",
    "print(\"Training loss:\", train_loss);\n",
    "print(\"Validation loss:\", val_loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "269db69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1 step:         5: Train loss 1.000, Eval loss1.000\n",
      "Epoch1 step:        10: Train loss 1.000, Eval loss1.000\n",
      "Epoch1 step:        15: Train loss 1.000, Eval loss1.000\n",
      "Epoch1 step:        20: Train loss 1.000, Eval loss1.000\n",
      "Epoch1 step:        25: Train loss 1.000, Eval loss1.000\n",
      "Epoch1 step:        30: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:        35: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:        40: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:        45: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:        50: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:        55: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:        60: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:        65: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:        70: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:        75: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:        80: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:        85: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:        90: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:        95: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:       100: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:       105: Train loss 0.000, Eval loss1.000\n",
      "Epoch1 step:       110: Train loss 0.000, Eval loss0.000\n",
      "new text: Below is an instruction that describes a task.Write a response that appropriately completes the request.  ### Instruction: Rewrite the sentence using alliteration.  ### Input: The wind blew softly.  ### Response: The wind blew a gentle breeze.<|endoftext|>### Response: The wind blew a gentle breeze.<|endoftext|>### Response: The wind blew a gentle breeze.<|endoftext|> ### Response: The wind blew a gentle breeze.\n",
      "Epoch2 step:       115: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       120: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       125: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       130: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       135: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       140: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       145: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       150: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       155: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       160: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       165: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       170: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       175: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       180: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       185: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       190: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       195: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       200: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       205: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       210: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       215: Train loss 0.000, Eval loss1.000\n",
      "Epoch2 step:       220: Train loss 0.000, Eval loss1.000\n",
      "new text: Below is an instruction that describes a task.Write a response that appropriately completes the request.  ### Instruction: Rewrite the sentence using alliteration.  ### Input: The wind blew softly.  ### Response: The wind came to life.<|endoftext|>### Response: The wind came to life.<|endoftext|>### Response: The wind came to life.<|endoftext|><|endoftext|>### Response: The wind came to life.<|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "Traning Finished, in1.23 minutes.\n"
     ]
    }
   ],
   "source": [
    "from GPTModel import train_model;\n",
    "import time;\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time();\n",
    "\n",
    "torch.manual_seed(123);\n",
    "\n",
    "# ‰ºòÂåñÂô®ËÆæÁΩÆ\n",
    "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.001);\n",
    "\n",
    "\n",
    "epochs = 2;\n",
    "\n",
    "train_loss, val_loss = train_model(model, \n",
    "           train_dataloader,\n",
    "           val_dataloader,\n",
    "            optimizer=optimizer, \n",
    "            device=device,\n",
    "            epochs=epochs,\n",
    "            tokenizer=tokenizer,\n",
    "            eval_interval=5,\n",
    "            \n",
    "            prompt=format_input(val_data[0]),)\n",
    "\n",
    "\n",
    "end_time = time.time();\n",
    "\n",
    "duration = (end_time-start_time)/60;\n",
    "print(f\"Traning Finished, in{duration:.2f} minutes.\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c3584",
   "metadata": {},
   "source": [
    "#  ‰øùÂ≠òÊ®°ÂûãÂà∞Êñá‰ª∂\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17bc992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_sft.pth\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d8ed79",
   "metadata": {},
   "source": [
    "# ÁªòÂà∂ÊçüÂ§±Ë∂ãÂäøÂõæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13776c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as  plt;\n",
    "\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    \"\"\"Safely convert any tensor to numpy array\"\"\"\n",
    "    return tensor.detach().cpu().numpy()\n",
    "\n",
    "def plot_loss(epochs, train_loss, val_loss ):\n",
    "    fig, ax = plt.subplots(figsize=(5, 3));\n",
    "    ax.plot(epochs, train_loss  , label=\"Traning loss\");\n",
    "    ax.plot(epochs, val_loss , label=\"Validation loss\");\n",
    "    ax.set_xlabel(\"epochs\");\n",
    "    ax.set_ylabel(\"Loss\");\n",
    "    ax.legend(loc=\"upper right\");\n",
    "    fig.tight_layout();\n",
    "\n",
    "x = torch.linspace(0, epochs, len(train_loss) );\n",
    "# ÊñπÊ≥ï2ÔºöÂàóË°®Êé®ÂØºÂºèÔºàÊúÄÂ∏∏Áî®Ôºâ\n",
    "train_loss_cpu_list = [tensor.cpu() for tensor in train_loss];\n",
    "val_loss_cpu_list = [tensor.cpu() for tensor in val_loss];\n",
    "plot_loss(x,  (train_loss_cpu_list),  (val_loss_cpu_list));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e175d79",
   "metadata": {},
   "source": [
    "# ÂçÅ„ÄÅ‰ΩøÁî®Ëá™Â∑±ËÆ≠ÁªÉÊ®°ÂûãÊé®ÁêÜ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c63f487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Explain the primary function of the human heart.\n",
      "\n",
      "Correct response:\n",
      ">> The primary function of the human heart is to pump blood throughout the body, delivering oxygen and nutrients to tissues and removing carbon dioxide and other wastes.\n",
      "\n",
      "Model response:\n",
      ">> The primary purpose of the heart is to supply the hungry children with the bus. It causes the movement at the base and affect ecosystems by moving at sea level.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Reword the following sentence to the future tense.\n",
      "\n",
      "### Input:\n",
      "He is reading a novel inspired by his grandmother.\n",
      "\n",
      "Correct response:\n",
      ">> He will be reading a novel inspired by his grandmother.\n",
      "\n",
      "Model response:\n",
      ">> He was reading a novel.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the given sentence into active voice.\n",
      "\n",
      "### Input:\n",
      "The law was passed by the government.\n",
      "\n",
      "Correct response:\n",
      ">> The government passed the law.\n",
      "\n",
      "Model response:\n",
      ">> The result was passed by the state government.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "for entry in test_data[:3]:                #A\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate_new(model,\n",
    "        text_to_tokenids(input_text, tokenizer).to(device),\n",
    "        256,\n",
    "        GPT_CONFIG_124M[\"max_seq_length\"],\n",
    "        25,\n",
    "        1.0,\n",
    "        50256)\n",
    "    generated_text = tokenids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\",\"\").strip()\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e42b632",
   "metadata": {},
   "source": [
    "#  ÂçÅ‰∏Ä„ÄÅÊ®°ÂûãËØÑÂàÜ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c50c68a",
   "metadata": {},
   "source": [
    "## ÁîüÊàêËØÑÂàÜÊµãËØïÊï∞ÊçÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1bb03b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 110/110 [00:20<00:00,  5.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from GPTModel import generate_new\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate_new(\n",
    "        model=model,\n",
    "        prompt=text_to_tokenids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_seq_size=GPT_CONFIG_124M[\"max_seq_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = tokenids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\",\n",
    "\"\").strip()\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4) # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "461f687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json;\n",
    "import urllib.request;\n",
    "\n",
    "\n",
    "def chat_model(prompt, model=\"qwen3:latest\", url=\"http://192.168.9.179:11434/api/chat\"):\n",
    "    data = {\n",
    "         \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"options\": {\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0.0\n",
    "        }\n",
    "    };\n",
    "\n",
    "    payload = json.dumps(data).encode(\"utf-8\");\n",
    "    request = urllib.request.Request(url, method=\"POST\", data=payload);\n",
    "    request.add_header(\"Content-Type\", \"application/json\");\n",
    "    content = \"\";\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode('utf-8');\n",
    "            if not line:\n",
    "                break;\n",
    "\n",
    "            response_json = json.loads(line);\n",
    "            # print(f\"response_json:{response_json}\");\n",
    "            content +=response_json[\"message\"][\"content\"];\n",
    "        return content;\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf2abeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‰Ω†Â•ΩÔºÅÊàëÊòØÈÄö‰πâÂçÉÈóÆÔºåÊòØÈÄö‰πâÂÆûÈ™åÂÆ§Á†îÂèëÁöÑË∂ÖÂ§ßËßÑÊ®°ËØ≠Ë®ÄÊ®°Âûã„ÄÇÊàëËÉΩÂ§üÂ∏ÆÂä©‰Ω†ÂõûÁ≠îÈóÆÈ¢ò„ÄÅÂàõ‰ΩúÊñáÂ≠ó„ÄÅÈÄªËæëÊé®ÁêÜ„ÄÅÁºñÁ®ãÁ≠âÔºåÊàëÁöÑÁõÆÊ†áÊòØËÆ©ÊØè‰∏™‰∫∫ÈÉΩËÉΩ‰æøÊç∑Âú∞‰ΩøÁî®‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØ„ÄÇËôΩÁÑ∂ÊàëÊ≤°Êúâ‰∏™‰∫∫ÊÉÖÊÑüÔºå‰ΩÜÊàëÂèØ‰ª•Êèê‰æõÂ∏ÆÂä©ÂíåÈô™‰º¥„ÄÇÊúâ‰ªÄ‰πàÈóÆÈ¢òÊàñÈúÄË¶ÅÂçèÂä©ÁöÑÂêóÔºüüòä\n"
     ]
    }
   ],
   "source": [
    "result = chat_model(\"‰Ω†Â•ΩÔºå‰Ω†ÊòØË∞ÅÔºü\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd45c033",
   "metadata": {},
   "source": [
    "# ËØÑÂàÜ‰ª£Á†ÅÂÆûÁé∞\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5168e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The primary function of the human heart is to pump blood throughout the body, delivering oxygen and nutrients to tissues and removing carbon dioxide and other wastes.\n",
      "\n",
      "Model response:\n",
      ">> The primary function of the heart is to supply the body with oxygen through breathing.\n",
      "\n",
      "Score:\n",
      ">> 0\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> He will be reading a novel inspired by his grandmother.\n",
      "\n",
      "Model response:\n",
      ">> He is reading a book.\n",
      "\n",
      "Score:\n",
      ">> 0\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The government passed the law.\n",
      "\n",
      "Model response:\n",
      ">> The law was passed by the government.\n",
      "\n",
      "Score:\n",
      ">> 0\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "with open(\"instruction-data-with-response.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    jsondata = json.load(f)\n",
    "#print(data[0])  \n",
    "for entry in jsondata[:3]:\n",
    "    prompt = (\n",
    "        f\" ÁªôÂÆö‰∏Ä‰∏™ËæìÂÖ•Ôºö `{format_input(entry)}` \"\n",
    "        f\" Ê≠£Á°ÆÁöÑËæìÂá∫‰∏∫: `{entry['output']}`, \"\n",
    "        f\" Ê®°ÂûãÁªôÁöÑËæìÂá∫‰∏∫Ôºö `{entry['model_response']}`\"\n",
    "        f\" ËØ∑‰∏∫Ê®°ÂûãÁöÑËæìÂá∫ÊâìÂàÜÔºå0Ë°®Á§∫ÊúÄÂ∑ÆÔºå100Ë°®Á§∫ÊúÄÂ•ΩÔºåÂè™ÁªôÂá∫ÂàÜÊï∞„ÄÇ\"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", chat_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98508d77",
   "metadata": {},
   "source": [
    "## ÊµãËØïËØÑÂàÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9abcabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 110/110 [24:15<00:00, 13.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 10.09\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def generate_model_scores(json_data):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"ÁªôÂÆö‰∏Ä‰∏™ËæìÂá∫Ôºö `{format_input(entry)}` \"\n",
    "            f\"Ê≠£Á°ÆÁöÑËæìÂá∫‰∏∫: `{entry['output']}`, \"\n",
    "            f\"Ê®°ÂûãÁªôÁöÑËæìÂá∫‰∏∫Ôºö `{entry['model_response']}`\"\n",
    "            f\" ËØ∑‰∏∫Ê®°ÂûãÁöÑËæìÂá∫ÊâìÂàÜÔºå0Ë°®Á§∫ÊúÄÂ∑ÆÔºå100Ë°®Á§∫ÊúÄÂ•ΩÔºåÂè™ÁªôÂá∫ÂàÜÊï∞„ÄÇ\"                       \n",
    "        )\n",
    "        score = chat_model(prompt)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores\n",
    "\n",
    "scores = generate_model_scores(jsondata)\n",
    "print(f\"Number of scores: {len(scores)} of {len(jsondata)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52448be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 10.09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of scores: {len(scores)} of {len(jsondata)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
