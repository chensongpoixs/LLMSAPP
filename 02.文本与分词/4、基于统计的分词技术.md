# 基于统计的分词技术

<font color='red'>字节对编码（Byte Pair Encoding）</font>


BPE(基于统计分词)的原理

1. BPE的训练过程想玩乐高积木
2. 从一些最基本的零散的积木（字符）开始
3. 把最常拼在一起的积木组合到一起形成新的积木
4. 不断的重复这个过程


## 一、 BPE的优缺点

### 1. 优点:

1. 完美处理未知词，最差情况是将不认识的词拆成单个字符
2. 词汇表大小可控
3. 压缩率高，一些高频词根，如ing,tion，会被合成一个token

### 2. 缺点

1. 采用贪心算法有局限，不一定是全局最优解


[OpenAI 使用BPE分词器地址：https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)


[OpenAI 分词器是开源的地址：https://github.com/openai/tiktoken](https://github.com/openai/tiktoken)



## 二、头部AI公司使用分词器


|分词器/库|核心思想/算法|标志性特点|主要使用者|
|:---:|:---:|:---:|:---:|
|OpenAI BPE(tiktoken)|Byte-level BPE|直接在字节流上操作，高效压缩|GPT-2,GPT-3,GPT-4,GPT-40, GPT-5|
|SentencePiece|BPE, Unigram|语言无关，无需预分词，空格视为|LLaMA, T5,多语言模型|
|WordPiece|Max-Likelihood|需要预分词，词中片段用 ## 标记|BERT 及其家族|
|Hugging Facetokenizers|BPE, WordPiece,Unigram..|集大成者，高性能Rust 实现，完整流水线|Hugging Face 生态所有模型|

















