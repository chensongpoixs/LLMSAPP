{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Author  : chensong\n",
    "# @File    : 红楼梦.py\n",
    "# @Time    : 2025-12-16 00:00\n",
    "# @Desc    : 爬取《红楼梦》所有章节标题和内容\n",
    "# 功能：爬取《红楼梦》所有章节标题和内容\n",
    "# 目标网站：https://hongloumeng.5000yan.com/\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# 红楼梦目录页地址\n",
    "base_url = \"https://hongloumeng.5000yan.com/\";\n",
    "\n",
    "\n",
    "# 数据保存路径\n",
    "save_path = \"./data/红楼梦.txt\"\n",
    "\n",
    "def book_spider(url):\n",
    "    \"\"\"\n",
    "    爬取红楼梦文本信息\n",
    "    :param url: 小说目录页网址\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 1. 进行UA伪装，模拟浏览器访问\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "    }\n",
    "    print(\"开始爬取《红楼梦》全文...\");\n",
    "    # 2. 发送请求\n",
    "    page_text = requests.get(url=url, headers=headers)\n",
    "    page_text.encoding = page_text.apparent_encoding # 自动获取编码防止乱码\n",
    "    page_text = page_text.text\n",
    "    # print(\"目录页爬取成功！page_tex:\", page_text);\n",
    "    # 3. 解析目录页，获取所有章节的链接和标题\n",
    "    soup = BeautifulSoup(page_text, 'lxml')\n",
    "\n",
    "\n",
    "\n",
    "    print(\"==========soup:\", soup);\n",
    "\n",
    "\n",
    "\n",
    "    # 选择器定位到所有包含章节链接的<a>标签\n",
    "    aTagList = soup.select('div > ul > li.p-2 > a');\n",
    "    print(\"==========aTagList:\", aTagList);\n",
    "    # return;\n",
    "    titleList = [i.text for i in aTagList] # 章节标题列表\n",
    "    #urlList = [\"https://www.shicimingju.com\" + i[\"href\"] for i in aTagList] # 补全为完整链接\n",
    "    urlList = [ i[\"href\"] for i in aTagList] # 补全为完整链接\n",
    "    # 4. 创建文件并写入总标题\n",
    "    with open(save_path, 'w', encoding='utf-8') as fp:\n",
    "        fp.write(\"红楼梦\\n\")\n",
    "    # 5. 遍历每一章，调用函数下载内容\n",
    "    for chp in zip(titleList, urlList):\n",
    "        write_chapter(chp)\n",
    "    print(\"《红楼梦》全文爬取完成！\")\n",
    "\n",
    "def write_chapter(content_list):\n",
    "    \"\"\"\n",
    "    提取单个章节内容并追加写入文件\n",
    "    :param content_list: 包含（标题, 链接）的元组\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    title, url = content_list\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "    # 请求章节详情页\n",
    "    page_text = requests.get(url=url, headers=headers, timeout=10)\n",
    "    page_text.encoding = page_text.apparent_encoding\n",
    "    page_text = page_text.text\n",
    "    # 解析章节正文内容\n",
    "    soup = BeautifulSoup(page_text, 'lxml')\n",
    "    content = soup.select('div > div > div.grap')  # 定位到正文内容的<p>标签列表\n",
    "    txt = \"\"\n",
    "    for i in content:\n",
    "        txt += i.text\n",
    "    # 将章节标题和内容追加到文件\n",
    "    with open(save_path, 'a', encoding='utf-8') as fp:\n",
    "        fp.write(\"{}\".format('\\n\\n' + title + '\\n'));\n",
    "        fp.write(txt + '\\n');\n",
    "    print(f\"已下载: {title}\");\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    book_spider(base_url)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
