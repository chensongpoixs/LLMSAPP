# 深度神经网络之初始化权重参数

## 权重初始化的方法

1. 0 初始化
2. 随机初始化
3. Xavier初始化
4. He初始化



### 1、 0 初始化


1. 将所有的权重初始化为0
2. 这种方式会带来严重问题，看个具体的例子
3. 当w=0时，wx+b=b，反向传播时梯度消失
4. 因此， 也无法有效训练模型

### 2、随机初始化

1. 使用均匀分布或正态分布的随机数初始化
2. 当随机数没有选好，也会出现梯度消失


### 3、Xavier初始化

1. 专门针对sigmoid/tanh激活函数的初始化方法
2. 可以使每一层输入与输出方差尽量保持一致
3. 有效防止梯度消失或爆炸
4. sigmoid/tanh很少使用，所以这种方法用的不多

### 4、He初始化


1. He是由何凯明团队发明的
2. 它是专门针对ReLU激活函数的初始化方法
3. 公式: ${\sqrt{\frac{2}{n}}}$


 